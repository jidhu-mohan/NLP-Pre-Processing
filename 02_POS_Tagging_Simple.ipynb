{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "# Part-of-Speech (POS) Tagging\n\n## What is POS Tagging?\n\n**Part-of-Speech (POS) tagging** is the process of assigning grammatical categories (noun, verb, adjective, etc.) to each word in a text based on its definition and context.\n\n### Why is it important?\n- **Word Disambiguation**: Words like \"book\" can be a noun or verb depending on context\n- **Information Extraction**: Helps identify entities, relationships, and key information\n- **Sentiment Analysis**: Identifies opinion words (adjectives, adverbs)\n- **Machine Translation**: Understanding sentence structure for better translation\n- **Text-to-Speech**: Correct pronunciation based on word type\n\n### Common POS Tags:\n- **NN**: Noun (singular) - dog, car\n- **NNS**: Noun (plural) - dogs, cars\n- **VB**: Verb (base form) - run, eat\n- **VBD**: Verb (past tense) - ran, ate\n- **VBG**: Verb (gerund) - running, eating\n- **JJ**: Adjective - big, beautiful\n- **RB**: Adverb - quickly, slowly\n- **DT**: Determiner - the, a\n- **IN**: Preposition - in, on, at"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.tag import DefaultTagger, UnigramTagger, BigramTagger\n",
    "from nltk.corpus import treebank\n",
    "\n",
    "nltk.download('punkt', quiet=True)\n",
    "nltk.download('averaged_perceptron_tagger', quiet=True)\n",
    "nltk.download('treebank', quiet=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## 1. Basic POS Tagging\n\nNLTK provides a pre-trained POS tagger that uses the Penn Treebank tag set. It's easy to use and works well for most English text."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence = \"The cat sits on the mat\"\n",
    "tokens = word_tokenize(sentence)\n",
    "pos_tags = nltk.pos_tag(tokens)\n",
    "\n",
    "print(f\"Sentence: {sentence}\\n\")\n",
    "for word, tag in pos_tags:\n",
    "    print(f\"{word:10} -> {tag}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## 2. Rule-Based Tagging\n\n**Rule-based taggers** use patterns and rules to assign POS tags. They match word endings or patterns to determine the tag.\n\n**Advantages:**\n- Simple and interpretable\n- No training data needed\n- Fast\n\n**Disadvantages:**\n- Limited accuracy\n- Can't handle context well\n- Requires manual rule creation"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Regular expression patterns\n",
    "patterns = [\n",
    "    (r'.*ing$', 'VBG'),    # gerunds\n",
    "    (r'.*ed$', 'VBD'),     # past tense\n",
    "    (r'.*ly$', 'RB'),      # adverbs\n",
    "    (r'.*s$', 'NNS'),      # plural nouns\n",
    "    (r'.*', 'NN')          # default\n",
    "]\n",
    "\n",
    "regexp_tagger = nltk.RegexpTagger(patterns)\n",
    "\n",
    "test = \"The cats are running quickly\"\n",
    "tokens = word_tokenize(test)\n",
    "print(f\"Sentence: {test}\\n\")\n",
    "print(regexp_tagger.tag(tokens))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## 3. Probabilistic Tagging\n\n**Probabilistic taggers** learn from annotated training data and use statistics to predict tags. They consider context and word frequencies.\n\n### Types:\n- **Unigram Tagger**: Assigns the most frequent tag for each word\n- **Bigram Tagger**: Considers the previous word's tag\n- **Trigram Tagger**: Considers the previous two tags\n\n**Advantages:**\n- Higher accuracy (85-95%)\n- Learn from data automatically\n- Handle context better\n\n**Backoff Chain**: If a tagger can't decide, it falls back to a simpler tagger (Bigram → Unigram → Default)"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare training data\n",
    "tagged_sentences = treebank.tagged_sents()\n",
    "split = int(len(tagged_sentences) * 0.8)\n",
    "train_data = tagged_sentences[:split]\n",
    "test_data = tagged_sentences[split:]\n",
    "\n",
    "print(f\"Training sentences: {len(train_data)}\")\n",
    "print(f\"Test sentences: {len(test_data)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train taggers\n",
    "default_tagger = DefaultTagger('NN')\n",
    "unigram_tagger = UnigramTagger(train_data, backoff=default_tagger)\n",
    "bigram_tagger = BigramTagger(train_data, backoff=unigram_tagger)\n",
    "\n",
    "# Evaluate\n",
    "print(\"Accuracy on test data:\\n\")\n",
    "print(f\"Unigram: {unigram_tagger.accuracy(test_data):.2%}\")\n",
    "print(f\"Bigram:  {bigram_tagger.accuracy(test_data):.2%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test on new sentence\n",
    "test_sent = \"The dog runs quickly through the garden\"\n",
    "tokens = word_tokenize(test_sent)\n",
    "\n",
    "print(f\"Sentence: {test_sent}\\n\")\n",
    "for word, tag in bigram_tagger.tag(tokens):\n",
    "    print(f\"{word:12} -> {tag}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## 4. Extracting Specific POS\n\nOnce we have POS tags, we can extract specific types of words for various applications:\n\n- **Nouns (NN, NNS)**: For keyword extraction, topic modeling\n- **Adjectives (JJ)**: For sentiment analysis, product features\n- **Verbs (VB*)**: For action identification, event extraction\n- **Named Entities (NNP, NNPS)**: For entity recognition\n\nThis is useful for:\n- Summarization\n- Information extraction\n- Search and indexing\n- Content analysis"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"The beautiful garden contains colorful flowers and tall trees\"\n",
    "tokens = word_tokenize(text)\n",
    "tagged = nltk.pos_tag(tokens)\n",
    "\n",
    "# Extract nouns\n",
    "nouns = [word for word, tag in tagged if tag in ['NN', 'NNS']]\n",
    "# Extract adjectives\n",
    "adjectives = [word for word, tag in tagged if tag.startswith('JJ')]\n",
    "\n",
    "print(f\"Text: {text}\\n\")\n",
    "print(f\"Nouns: {nouns}\")\n",
    "print(f\"Adjectives: {adjectives}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}